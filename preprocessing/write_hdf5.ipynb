{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79ae5b1b",
   "metadata": {},
   "source": [
    "# Write DHS images as HDF5\n",
    "\n",
    "In order to speed up loading, and avoid this from being a bottleneck during training, we save the DHS images as a HDF5 file. This will be much faster than reading an individual .np file for each image during training. For more information about this, see the [h5py website](https://www.h5py.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "465d46d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import configparser\n",
    "\n",
    "# Read config file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('../config.ini')\n",
    "\n",
    "DATA_DIR = config['PATHS']['DATA_DIR']\n",
    "\n",
    "df = pd.read_csv(os.path.join(DATA_DIR, 'dhs_with_imgs.csv'))\n",
    "img_dir = os.path.join(DATA_DIR, 'dhs_images')\n",
    "\n",
    "hdf5_path = os.path.join(DATA_DIR, 'dhs_images.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01021cb3",
   "metadata": {},
   "source": [
    "Write as .h5-file. This took me about an hour and a half on Alvis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b0e505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [03:44<00:00, 44.47it/s]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(hdf5_path, 'w') as h5f:\n",
    "    for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        cluster_id = row['cluster_id']\n",
    "        img_path = os.path.join(img_dir, cluster_id, 'landsat.np')\n",
    "        try:\n",
    "            img = np.load(img_path)  # shape: (H, W, 6)\n",
    "            img = img.astype(np.uint16)  # Convert to uint16\n",
    "            h5f.create_dataset(str(i), data=img, compression=\"gzip\")\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {img_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2c0a86",
   "metadata": {},
   "source": [
    "Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "317ffeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datasets in HDF5 file: 68619\n",
      "Keys in HDF5 file: ['AO.Bengo.71.135', 'AO.Bengo.71.158', 'AO.Bengo.71.169', 'AO.Bengo.71.203', 'AO.Bengo.71.208']\n",
      "Shape of first dataset: (224, 224, 6)\n",
      "Data type of first dataset: uint16\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(hdf5_path, 'r') as h5f:\n",
    "    print(f\"Number of datasets in HDF5 file: {len(h5f)}\")\n",
    "    print(f\"Keys in HDF5 file: {list(h5f.keys())[:5]}\")  # Show first 5 keys\n",
    "    print(f\"Shape of first dataset: {h5f[list(h5f.keys())[0]].shape}\")  # Shape of the first dataset\n",
    "    print(f\"Data type of first dataset: {h5f[list(h5f.keys())[0]].dtype}\")  # Data type of the first dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea495193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class RegressionDataset(Dataset):\n",
    "    def __init__(self, df, hdf5_path, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.hdf5_path = hdf5_path\n",
    "        self.transform = transform\n",
    "        self.h5_file = None  # Will be initialized lazily in __getitem__\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.h5_file is None:\n",
    "            self.h5_file = h5py.File(self.hdf5_path, 'r')\n",
    "\n",
    "        cluster = self.df.iloc[idx]\n",
    "        img = self.h5_file[cluster['cluster_id']][:].astype(np.float32)\n",
    "        target = cluster['iwi'] / 100\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __del__(self):\n",
    "        if self.h5_file is not None:\n",
    "            self.h5_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "727ec409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 3772/68619 [00:18<05:14, 205.95it/s]\n",
      "Exception ignored in: <function RegressionDataset.__del__ at 0x15321ac27f70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/local/tmp.4735263/ipykernel_3048466/2471170545.py\", line 27, in __del__\n",
      "AttributeError: 'RegressionDataset' object has no attribute 'h5_file'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m ds \u001b[38;5;241m=\u001b[39m RegressionDataset(df, hdf5_path)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img, target \u001b[38;5;129;01min\u001b[39;00m tqdm(ds):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [6], line 18\u001b[0m, in \u001b[0;36mRegressionDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh5_file \u001b[38;5;241m=\u001b[39m h5py\u001b[38;5;241m.\u001b[39mFile(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhdf5_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m cluster \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39miloc[idx]\n\u001b[0;32m---> 18\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mh5_file\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcluster\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcluster_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     19\u001b[0m target \u001b[38;5;241m=\u001b[39m cluster[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miwi\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/h5py/_hl/dataset.py:758\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, args, new_dtype)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fast_read_ok \u001b[38;5;129;01mand\u001b[39;00m (new_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 758\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fast_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    759\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    760\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall back to Python read pathway below\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ds = RegressionDataset(df, hdf5_path)\n",
    "\n",
    "for img, target in tqdm(ds):\n",
    "    pass  # Just iterating through the dataset to ensure it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "912efcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_workers = 32\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(ds, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccad6952",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 537/537 [00:42<00:00, 12.63it/s]\n"
     ]
    }
   ],
   "source": [
    "for batch in tqdm(dataloader):\n",
    "    imgs, targets = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f0d9482",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/537 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 537/537 [00:33<00:00, 16.23it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_workers = 16\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(ds, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True, persistent_workers=True)\n",
    "\n",
    "for batch in tqdm(dataloader):\n",
    "    imgs, targets = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8b38085",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "class RegressionDataset(Dataset):\n",
    "    def __init__(self, df, hdf5_path, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.hdf5_path = hdf5_path\n",
    "        self.transform = transform\n",
    "        self.h5_file = None  # Will be initialized lazily in __getitem__\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.h5_file is None:\n",
    "            self.h5_file = h5py.File(self.hdf5_path, 'r')\n",
    "\n",
    "        cluster = self.df.iloc[idx]\n",
    "        img = self.h5_file[cluster['cluster_id']][:].astype(np.float32)\n",
    "        target = cluster['iwi']\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, target\n",
    "\n",
    "    def __del__(self):\n",
    "        if self.h5_file is not None:\n",
    "            self.h5_file.close()\n",
    "\n",
    "def get_dataloaders(df, hdf5_path, train_folds, val_fold, test_fold, batch_size=128, num_workers=16):\n",
    "\n",
    "    # Get the indices for each fold\n",
    "    train_folds = df[df['cv_fold'].isin(train_folds)].index.tolist()\n",
    "    val_fold = df[df['cv_fold'] == val_fold].index.tolist()\n",
    "    test_fold = df[df['cv_fold'] == test_fold].index.tolist()\n",
    "\n",
    "    train_dataset = RegressionDataset(df=df.iloc[train_folds], hdf5_path=hdf5_path, transform=None)\n",
    "    val_dataset = RegressionDataset(df=df.iloc[val_fold], hdf5_path=hdf5_path, transform=None)\n",
    "    test_dataset = RegressionDataset(df=df.iloc[test_fold], hdf5_path=hdf5_path, transform=None)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True, persistent_workers=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True, persistent_workers=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    return train_dataloader, val_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e20372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create equal-sized folds\n",
    "folds = ['A', 'B', 'C', 'D', 'E']\n",
    "df['cv_fold'] = np.nan  # Initialize the cv_fold column\n",
    "\n",
    "# Generate and shuffle indices\n",
    "indices = np.arange(len(df))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Split indices into equal-sized groups and assign folds\n",
    "fold_indices = np.array_split(indices, len(folds))\n",
    "for fold, idx in zip(folds, fold_indices):\n",
    "    df.loc[idx, 'cv_fold'] = fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b7b70b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train folds: ['C', 'D', 'E'], Validation fold: B, Test fold: A\n"
     ]
    }
   ],
   "source": [
    "fold = 'A'  # Specify the fold you want to use for testing\n",
    "batch_size = 128\n",
    "\n",
    "# Define train, validation, and test folds\n",
    "test_fold = fold\n",
    "val_fold = folds[(folds.index(fold) + 1) % len(folds)]\n",
    "train_folds = [f for f in folds if f not in [test_fold, val_fold]]\n",
    "print(f\"Train folds: {train_folds}, Validation fold: {val_fold}, Test fold: {test_fold}\")\n",
    "\n",
    "# Get dataloaders\n",
    "train_dataloader, val_dataloader, test_dataloader = get_dataloaders(df, hdf5_path, train_folds, val_fold, test_fold, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27cd7eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 322/322 [00:19<00:00, 16.36it/s]\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "landsat_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: x * 0.0000275 - 0.2),\n",
    "    transforms.Lambda(lambda x: torch.clamp(x, 0.0, 0.3)),\n",
    "    transforms.Lambda(lambda x: x / 0.3)\n",
    "])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    landsat_transform,\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip()\n",
    "])\n",
    "\n",
    "for batch in tqdm(train_dataloader):\n",
    "    imgs, targets = batch\n",
    "    imgs = train_transform(imgs.to(device, dtype=torch.float32, memory_format=torch.channels_last))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9e758c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
