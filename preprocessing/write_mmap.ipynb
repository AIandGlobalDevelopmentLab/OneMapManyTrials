{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write DHS images as MMAP\n",
    "\n",
    "In order to speed up loading, and avoid this from being a bottleneck during training, we save the DHS images as a memory map (MMAP). This will be much faster than reading an individual .np file for each image during training. This MMAP will take up more storage, but given the speed-up, it's a worthy trade-off. For more information about this, see the [MMAP Ninja library](https://github.com/hristo-vrigazov/mmap.ninja?tab=readme-ov-file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmap_ninja\n",
    "from mmap_ninja.ragged import RaggedMmap\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import configparser\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Read config file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('../config.ini')\n",
    "\n",
    "DATA_DIR = config['PATHS']['DATA_DIR']\n",
    "\n",
    "df = pd.read_csv(os.path.join(DATA_DIR, 'dhs_with_imgs.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the paths to the DHS images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 68619 DHS images\n"
     ]
    }
   ],
   "source": [
    "dhs_img_paths = df['cluster_id'].apply(lambda x: os.path.join(DATA_DIR, 'dhs_images', x, 'landsat.np'))\n",
    "dhs_img_paths = dhs_img_paths.tolist()\n",
    "print(f'Found {len(dhs_img_paths)} DHS images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the images as a memory map. This will take a couple of minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29681it [04:47, 216.39it/s]"
     ]
    }
   ],
   "source": [
    "# Once per project, convert the images to a memory map\n",
    "RaggedMmap.from_generator(\n",
    "    # Directory in which the memory map will be persisted\n",
    "    out_dir=os.path.join(DATA_DIR, 'dhs_images_ragged_mmap'),\n",
    "    sample_generator=map(np.load, dhs_img_paths),\n",
    "    # Maximum number of samples to keep in memory before flushing to disk\n",
    "    batch_size=1024,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print('Memory map created successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test loading and iterating over the MMAP. It should now take less than a second to iterate through the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/68619 [00:00<?, ?it/s]/local/tmp.4716309/ipykernel_3628384/798732472.py:8: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:199.)\n",
      "  img_tensor = torch.from_numpy(img)\n",
      "100%|██████████| 68619/68619 [00:00<00:00, 321951.23it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Open the memory map\n",
    "images_mmap = np_ninja.open_existing(os.path.join(DATA_DIR, 'dhs_images_mmap'))\n",
    "\n",
    "for i in tqdm(range(len(images_mmap))):\n",
    "    img: np.ndarray = images_mmap[i]\n",
    "    img_tensor = torch.from_numpy(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/68619 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 36828/68619 [00:32<00:28, 1133.49it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m img: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m=\u001b[39m images_mmap[img_i]\n\u001b[1;32m     17\u001b[0m img_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(img)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mbatch_tensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_i\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m img_tensor\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (df_i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m batch_size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     21\u001b[0m     batch_tensor\u001b[38;5;241m.\u001b[39mzero_()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from mmap_ninja import numpy as np_ninja\n",
    "\n",
    "# Open the memory map\n",
    "images_mmap = np_ninja.open_existing(os.path.join(DATA_DIR, 'dhs_images_mmap'))\n",
    "\n",
    "s_df = df.sample(frac=1).reset_index(drop=True)  # Shuffle the DataFrame for demonstration\n",
    "\n",
    "batch_size = 32  # Define your batch size\n",
    "batch_list = []\n",
    "\n",
    "batch_tensor = torch.empty((batch_size, 224, 224, 6), dtype=torch.float32)  # adjust dtype & shape\n",
    "\n",
    "for df_i in tqdm(np.arange(len(df))):\n",
    "    img_i = s_df.iloc[df_i].name\n",
    "    img: np.ndarray = images_mmap[img_i]\n",
    "    img_tensor = torch.from_numpy(img)\n",
    "    \n",
    "    batch_tensor[df_i % batch_size] = img_tensor\n",
    "    if (df_i + 1) % batch_size == 0:\n",
    "        batch_tensor.zero_()  # Reset the batch tensor for the next batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 36/537 [00:36<08:30,  1.02s/it]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mmap_ninja import numpy as np_ninja\n",
    "\n",
    "class SimpleDataLoader:\n",
    "    def __init__(self, df, img_mmap, transform=None, shuffle=False, batch_size=1):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_mmap = img_mmap\n",
    "        self.transform = transform\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = batch_size\n",
    "        self.indices = np.arange(len(self.df))\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "        self.ptr = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.ptr >= len(self.indices):\n",
    "            raise StopIteration\n",
    "\n",
    "        # Select batch indices\n",
    "        batch_indices = self.indices[self.ptr:self.ptr + self.batch_size]\n",
    "        self.ptr += self.batch_size\n",
    "\n",
    "        # Fetch batch\n",
    "        images = []\n",
    "        targets = []\n",
    "\n",
    "        for idx in batch_indices:\n",
    "            row = self.df.iloc[idx]\n",
    "            img = torch.from_numpy(self.img_mmap[idx])\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            images.append(img)\n",
    "            targets.append(row['iwi'] / 100)\n",
    "\n",
    "        # Stack if batch size > 1, else return single items\n",
    "        if self.batch_size == 1:\n",
    "            return images[0], targets[0]\n",
    "        else:\n",
    "            return np.stack(images), np.array(targets)\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.df) + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "dl = SimpleDataLoader(\n",
    "    df=s_df,\n",
    "    img_mmap=images_mmap,\n",
    "    transform=None,\n",
    "    shuffle=True,\n",
    "    batch_size=128\n",
    ")\n",
    "\n",
    "for batch_images, batch_targets in tqdm(dl):\n",
    "    continue  # Process your batch here, e.g., pass to a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68619/68619 [00:04<00:00, 14699.70it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class RegressionDatasetMMAP(Dataset):\n",
    "    def __init__(self, df, images_mmap, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_mmap = images_mmap\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cluster = self.df.iloc[idx]\n",
    "        img = self.img_mmap[cluster.name]\n",
    "        target = (cluster['iwi'] / 100)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, target\n",
    "\n",
    "ds = RegressionDatasetMMAP(\n",
    "    df=s_df,\n",
    "    images_mmap=images_mmap,\n",
    "    transform=None  # Add any transformations if needed\n",
    ")\n",
    "\n",
    "for img, target in tqdm(ds):\n",
    "    img_tensor = torch.from_numpy(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/68619 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 20658161664 into shape (224,224,6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 30\u001b[0m\n\u001b[1;32m     24\u001b[0m ds \u001b[38;5;241m=\u001b[39m RegressionDatasetMMAP(\n\u001b[1;32m     25\u001b[0m     df,\n\u001b[1;32m     26\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(DATA_DIR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdhs_images_mmap\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Loop through the dataset\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img, target \u001b[38;5;129;01min\u001b[39;00m tqdm(ds):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Process the image and target as needed\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [21], line 17\u001b[0m, in \u001b[0;36mRegressionDatasetMMAP.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     15\u001b[0m cluster \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39miloc[idx]\n\u001b[1;32m     16\u001b[0m cluster_id \u001b[38;5;241m=\u001b[39m cluster[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 17\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_mmap\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcluster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     18\u001b[0m target \u001b[38;5;241m=\u001b[39m (cluster[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miwi\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/mmap_ninja/ragged.py:93\u001b[0m, in \u001b[0;36mRaggedMmap.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaggedMmap is empty!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(item):\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_multiple(item)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/mmap_ninja/ragged.py:115\u001b[0m, in \u001b[0;36mRaggedMmap.get_single\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    113\u001b[0m         res \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 115\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrapper_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy_before_wrapper_fn:\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 20658161664 into shape (224,224,6)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from mmap_ninja.ragged import RaggedMmap\n",
    "\n",
    "class RegressionDatasetMMAP(Dataset):\n",
    "    def __init__(self, df, img_mmap_path, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_mmap = RaggedMmap(img_mmap_path, wrapper_fn=torch.tensor)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cluster = self.df.iloc[idx]\n",
    "        cluster_id = cluster['cluster_id']\n",
    "        img = self.img_mmap[cluster.name]\n",
    "        target = (cluster['iwi'] / 100)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, target\n",
    "\n",
    "# Example usage\n",
    "ds = RegressionDatasetMMAP(\n",
    "    df,\n",
    "    os.path.join(DATA_DIR, 'dhs_images_mmap'),\n",
    ")\n",
    "\n",
    "# Loop through the dataset\n",
    "for img, target in tqdm(ds):\n",
    "    # Process the image and target as needed\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
